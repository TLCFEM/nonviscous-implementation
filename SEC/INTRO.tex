\section{Introduction}
In the realm of structural dynamics and mechanical systems, the investigation of damping mechanisms plays a pivotal role in comprehending and optimising structural responses to external forces. Damping, the force that dissipates energy, is a critical factor shaping the dynamic behaviour of systems. Viscous and nonviscous damping represent fundamental categories characterising diverse energy dissipation mechanisms. Viscous damping serves as a prevalent and straightforward model, assuming a proportional relationship between damping force and velocity. In contrast, nonviscous damping encompasses a broader spectrum of models deviating from the linear correlation observed in viscous damping. Nonviscous damping models, unlike their viscous counterparts, may incorporate nonlinear relationships or more intricate functions to accurately portray energy dissipation.

The equation of motion of nonviscously damped systems can be, conventionally, expressed as an integro-differential equation, namely, for elastic multi-degree-of-freedom (MDOF) systems,
\begin{gather}\label{eq:single_eom}
\mb{M}\ba+g*\bv+\mb{K}\bu=\bm{p},
\end{gather}
where $\mb{p}=\mb{p}\left(t\right)$ is the external load vector, $\bu=\bu\left(t\right)$, $\bv=\bv\left(t\right)=\dot{\bu}$ and $\ba=\ba\left(t\right)=\dot{\bv}$ are the displacement, velocity and acceleration vectors, $\mb{M}$ and $\mb{K}$ are the mass and stiffness matrices, and $g=g(t)$ is the kernel function. Here the scalar version is used for the ease of discussion, in alternative formulations, it can also be a vector of different kernel functions. The kernel function can possess various forms, see a summary by \citet[][Table 1]{Adhikari2003}. The comparisons of different kernel functions are not discussed in this work, the interested reader may refer to, for example, the work by \citet{Impraimakis2022} and \citet{Impraimakis2023}. The convolution term in \eqsref{eq:single_eom} can be expressed in the integral form such that
\begin{gather}\label{eq:conv}
\left(g*\bv\right)\left(t\right)=\int_0^tg\left(t-\tau\right)\bv\left(\tau\right)\md{\tau}.
\end{gather}
To solve \eqsref{eq:single_eom}, \eqsref{eq:conv} needs to be evaluated. Numerous analytical and numerical methods have been proposed, each exhibiting distinct applicability. Given the scope limitations, we focus solely on delineating the characteristics of major methods. Consequently, it is important to note that the following discussion does not purport to offer a comprehensive review of all available methods.
\subsection{Direct/Explicit Integration Methods}
Assuming $\bv(t)$ is already obtained up to a given time $T$ at each sampling point $t_i$, \eqsref{eq:conv} can be numerically integrated such that
\begin{gather}
\int_0^Tg\left(T-\tau\right)\bv\left(\tau\right)\md{\tau}\approx\sum_i^n\omega_i\bv\left(t_i\right),
\end{gather}
where $t_i=\left\{t_1,t_2,\cdots,t_n\right\}\in[0,T]$ that can be either evenly or unevenly spaced, and $\omega_i$ is the corresponding integration weight that may directly contain or can be associated \citep{Schaedle2006} with the kernel term $g\left(T-t_i\right)$. If the exact $\bv(t_i)$ is not available, approximations (interpolation, weighted sum, etc.) based on adjacent known values can be adopted. A generalisation adopts fractional calculus \citep[e.g.,][]{Bagley1983,Gaul1999} in $g(t)$, which yields a simple form in the frequency domain, relevant analytical techniques can be applied. For further discussions, see, for example, the work by \citet{Fernandez2019}.

Such a direct approach, known as convolution quadrature \citep[see][and the references therein]{Lubich2004}, is general--purpose such that it can be used for both linear and nonlinear systems with either explicit or implicit time integration methods \citep[see, e.g.,][]{Katsikadelis2019}. The simplest integration one can come up with is the rectangle rule, which is used in the implementation by \citet{Puthanpurayil2014}. Noting that the rectangle rule possesses the lowest order of accuracy possible, it effectively yields low-order overall accuracy --- even when the adopted time integration method is second-order accurate. To improve, trapezoidal rule \citep[e.g.,][]{Liu2014} and Simpson's rules \citep[e.g.,][]{Shen2019} can be used. If necessary, other high-order Newton--Cotes rules and/or more complex approximations \citep{Schaedle2006,Shen2021}, such as the cubic B-spline based interpolation \citep{Liu2023a,Liu2023b}, can also be adopted.

In the context of dynamic analysis, accounting for the fact that most direct time integration methods (such as the Newmark method) are second-order accurate, \eqsref{eq:conv} has to be integrated with methods with at least a second-order accuracy. For methods of this kind, a potential improvement of overall computational efficiency is to use a fast converging method \citep{Schaedle2006} such that a large step size can be used for convolution quadrature. As a result, fewer velocity snapshots need to be stored, and the constant factor in complexity $\mathcal{O}\left(n^2\right)$ can be lowered.
Alternatively, noting that $\mathcal{L}\left(f*g\right)=\mathcal{L}\left(f\right)\cdot\mathcal{L}\left(g\right)$ where $\mathcal{L}$ stands for Laplace transform, it is possible to compute \eqsref{eq:conv} in the frequency domain via fast Fourier transform, rather than directly in the time domain, relevant applications can be seen elsewhere \citep{Pan2013,Zhao2019}.

However, no matter how the convolution term is integrated, it has to be performed for \textbf{each} substep and the \textbf{whole} velocity history needs to be stored. As a result, the space complexity depends on the temporal resolution (the number of substeps analysed). Besides, given the nature of convolution, most intermediate results computed in the current substep cannot be reused in subsequent substeps. The potential exception is the values of $g$ evaluated at $T-t_i$, which do not need to be re-evaluated if $T$ and $t_i$ satisfy certain conditions. For response history analyses, since velocity is computed at discrete time moments, existing methods typically use a fixed time step size and the same set of $t_i$ in both response history analysis (to define time substeps) and numerical integration of \eqsref{eq:conv} (as the abscissae), this gives a complexity of $\mathcal{O}\left(n^2\right)$ where $n$ denotes the number of substeps. The explicit integration also requires additional kinetic assumptions, that may conflict against the ones adopted by the corresponding time integration method, to be imposed. They have significant impacts on the final analysis outcome \citep[see,][]{Liu2014} and may even lead to poor results \cite[see,][Figs. 12, 17, 25, 26]{Liu2023}.
\subsection{State Space Methods}
With the assist of Laplace transform, the convolution term involving (sum of) exponential kernels (and potentially other functions) can be eliminated at the cost of increasing the order of time derivatives \citep[see, e.g.,][]{Wu2019}. By further introducing additional state variables, the second-order system \eqsref{eq:single_eom} can be converted into a first-order one, with which methods such as modal analysis\footnote{Noting that polynomial eigenvalue problems are essentially equivalent to generalised eigenvalue problems.} can be applied to obtain analytical solutions for linear systems.

Although state space methods allow analysts to obtain closed-form solutions, only kernels that possess simple forms in the $s$-domain can be considered. If the characteristic equation in the $s$-domain is a transcendental function or a higher order polynomial (the Abel--Ruffini theorem), the system would still be solved numerically in the sense that the eigenvalues can only be computed imprecisely. The converted first-order ODE can also be solved via numerical integration \citep{Adhikari2004,Ding2016}.
In essence, instead of `direct integrating' the second-order ODE, state space methods now integrate the first-order equivalence with proper kinematics assumptions.
However, since the order is lowered, its size increases accordingly. This often drastically increases computational costs. For further discussions on methods of this kind, one can refer to the summary by \citet[][\S~1.3.1]{Adhikari2014}.
To further improve accuracy, complex integration rules can also be adopted. For example, the precise integration method \citep{Zhong1994} that is initially proposed as a general time integration method for ODEs, and its derivations \citep[e.g.,][]{Wang2008}, is revised and adopted to integrate the corresponding first-order system in the state space \citep[see, e.g.,][]{Wang2018,Ding2018,Abbasi2019,Abbasi2022}.
Methods of this category typically involve exponentials of matrices, the computation of which is often costly in terms of both time and space as the banded structure of the original matrix can no longer be retained.
\subsection{Need of An Efficient Approach}
Based on the above discussion, nonviscously damped systems would better be solved by an algorithm that possesses the following attributes.
\begin{Objective}
\begin{enumerate}
\item It preserves the size of the original dynamic system.
\item It maintains the accuracy of the time integration method used.
\item It eliminates the need to integrate the convolution term for each substep and has a constant memory storage/space requirement.
\item It can be used with various time integration methods and kernels in both elastic/inelastic systems.
\end{enumerate}
\end{Objective}

This work presents an algorithm to incorporate arbitrary smooth kernels with direct time integration methods and explains the strategy in two parts.
\begin{enumerate}
\item For exponential kernels or kernels that can be expressed as sums of exponentials, a nonviscously damped system can be equivalently rewritten into a second-order ODE and a first-order ODE. Both can be discretised and solved directly in the time domain with a performant formulation. This part is presented in \secref{sec:single}.
\item Arbitrary smooth kernels can be approximated by sums of exponentials in a way that is independent of the dynamic system of interest. The approximation balances well between accuracy and efficiency. This part is discussed in \secref{sec:arbitrary}.
\end{enumerate}
Examples are presented in \secref{sec:example} with an emphasis on accuracy by comparing numerical results with analytical solutions (if available).

\section{Introduction}
The equation of motion of nonviscously damped systems can be, conventionally, expressed as an integro-differential equation, namely, for elastic linear single-degree-of-freedom systems,
\begin{gather}\label{eq:single_eom}
m\ddot{u}\left(t\right)+\left(g*\dot{u}\right)\left(t\right)+ku\left(t\right)=p\left(t\right),
\end{gather}
where $u(t)$ denotes the displacement, $\dot{(\cdot)}$ denotes time derivative, and $g=g(t)$ is the kernel function. Various forms have been proposed, see a summary by \citet[][Table 1]{Adhikari2003}.

The convolution term in \eqsref{eq:single_eom} can be expressed in integral form such that
\begin{gather}\label{eq:conv}
\left(g*\dot{u}\right)\left(t\right)=\int_0^tg\left(t-\tau\right)\dot{u}\left(\tau\right)\md{\tau}.
\end{gather}
To solve \eqsref{eq:single_eom} numerically, \eqsref{eq:conv} needs to be evaluated. Different approaches are available, we discuss major ones in the following.
\subsection{Direct Integration Methods}
Assuming $\dot{u}(t_i)$ is already obtained up to a given time $T$ at each sampling point $t_i$, \eqsref{eq:conv} can be numerically integrated such that
\begin{gather}
\int_0^Tg\left(T-\tau\right)\dot{u}\left(\tau\right)\md{\tau}\approx\sum_i^n\omega_i\dot{u}\left(t_i\right),
\end{gather}
where $t_i=\left\{t_0,t_1,t_2,\cdots,t_n\right\}\in[0,T]$ that can be either evenly or unevenly spaced, and $\omega_i$ is the corresponding integration weight that may directly contain or can be computed \citep{Schaedle2006} from the term $g\left(T-t_i\right)$. If the exact $\dot{u}(t_i)$ is not available, approximations (interpolation, weighted sum, etc.) based on adjacent known values are often adopted. A generalisation adopts fractional calculus \citep[e.g.,][]{Bagley1983,Gaul1999} in $g(t)$, which yields a simple form in the frequency domain, relevant analytical techniques can be applied. For further discussions, see, for example, the work by \citet{Fernandez2019}.

Such a direct approach, known as convolution quadrature \citep{Lubich2004}, is general--purpose such that it can be used for both linear and nonlinear systems with either explicit or implicit time integration methods \citep[see, e.g.,][]{Katsikadelis2019}. The simplest integration one can come up with is the rectangle rule, which is used in the implementation by \citet{Puthanpurayil2014}. Noting that the rectangle rule possesses the lowest order of accuracy possible, it effectively yields low-order overall accuracy --- even when the adopted time integration method is second-order accurate. To improve, trapezoidal rule \citep[see][]{Liu2014} and Simpson's rules \citep[see][]{Shen2019} can be used. If necessary, other high-order Newton--Cotes rules and/or more complex approximations \citep{Schaedle2006,Shen2021} can also be adopted.

However, no matter how the convolution term is integrated, it has to be performed for \textbf{each} substep and the whole velocity history needs to be stored. Given the nature of convolution, most intermediate results computed in the current substep cannot be reused in subsequent substeps. The potential exception is the values of $g$ evaluated at $T-t_i$, which do not need to be re-evaluated if $T$ and $t_i$ satisfy certain conditions. Existing methods typically use the same set of $t_i$ in both response history analysis (to define time substeps) and numerical integration of \eqsref{eq:conv} (as the abscissae), this gives a complexity of $\mathcal{O}\left(n^2\right)$ where $n$ denotes the number of substeps. The explicit integration also requires additional kinetic assumptions, that may conflict against the ones adopted by the corresponding time integration method, to be imposed. They have significant impacts on the final analysis result \citep[see][]{Liu2014} and may even lead to poor result \cite[see][Figs. 12, 17, 25, 26]{Liu2023}.

In the context of dynamic analysis, since most direct time integration methods (such as the Newmark method) are second-order accurate, \eqsref{eq:conv} has to be integrated with methods with at least a second-order accuracy. For methods of this kind, a potential improvement of overall computational efficiency is to use a fast converging method \citep{Schaedle2006} such that for convolution quadrature, a large step size can be used. As a result, fewer velocity snapshots need to be stored, and the constant factor in complexity $\mathcal{O}\left(n^2\right)$ can be lowered.

Noting that $\mathcal{L}\left(f*g\right)=\mathcal{L}\left(f\right)\cdot\mathcal{L}\left(g\right)$ where $\mathcal{L}$ stands for Laplace transform, it is possible to improve the computational efficiency by computing \eqsref{eq:conv} in the frequency domain via fast Fourier transform, rather than directly in the time domain, this reduces the complexity from $\mathcal{O}\left(n^2\right)$ to $\mathcal{O}\left(n\log\left(n\right)\right)$, relevant applications can be seen elsewhere \citep{Zhao2019}.
\subsection{State Space Methods}
With the assist of Laplace transform, the convolution term involving (sum of) exponential kernels (and potentially other functions) can be eliminated at the cost of increasing the order of time derivatives \citep[see, e.g.,][]{Wu2019}. By further introducing additional state variables, the second-order system \eqsref{eq:single_eom} can be converted into a first-order one, with which methods such as modal analysis\footnote{Noting that polynomial eigenvalue problems are essentially equivalent to generalised eigenvalue problems.} can be applied to obtain analytical solutions for linear systems.

Although state space methods allow analysts to obtain closed-form solutions, only kernels that possess simple forms in $s$-domain can be considered. If the characteristic equation is $s$-domain is a transcendental function or a higher order polynomial (the Abel--Ruffini theorem), the system would still be solved numerically in the sense that the eigenvalues can only be computed imprecisely. The converted first-order ODE can also be solved via numerical integration. However, since the order is lowered, its size increases accordingly. This often drastically increases computational costs.
\subsection{Need of An Efficient Approach}
Based on the above discussion, nonviscously damped systems would better be solved by an algorithm that possesses the following attributes.
\begin{Objective}
\begin{enumerate}
\item It preserves the size of the original dynamic system.
\item It maintains the accuracy of the time integration method used.
\item It eliminates the need to integrate the convolution term for each substep.
\item It can be used with various time integration methods and kernels in both elastic/inelastic systems.
\end{enumerate}
\end{Objective}

This work presents an algorithm to incorporate arbitrary smooth kernels with direct time integration methods and explains the strategy in two parts.
\begin{enumerate}
\item For exponential kernels or kernels that can be expressed as sums of exponentials, a nonviscously damped system can be equivalently rewritten into a second-order ODE and a first-order ODE. Both can be discretised and solved directly in the time domain with a performant formulation.
\item Arbitrary smooth kernels can be approximated by sums of exponentials in a way that is independent of the dynamic system of interest. The approximation balances well between accuracy and efficiency.
\end{enumerate}
Examples are presented with an emphasis on accuracy by comparing numerical results with analytical solutions (if available).
